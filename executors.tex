% !TEX root = main.tex

\section{Symbolic Executors}
\label{se:executors}

\subsection{Concrete, Concolic, and Symbolic Execution}
\label{ss:concrete-concolic-symbolic}

[...]

\subsection{Principles of Symbolic Executors}\mynote{[D] Entirely rewritten}
\label{ss:principles}

\cite{MAYHEM-SP12} discusses a number design principles that a symbolic execution engine should follow, most notably: 
%A symbolic execution engine should guarantee three main principles (\cite{MAYHEM-SP12}):
\begin{enumerate}
  \item the system should be able to make forward progress for an arbitrarily long time (ideally forever) without exceeding the given resources;
  \item to maximize performance, no work should be repeated (e.g., avoid restarting symbolic/concrete execution of a program from the beginning);
  \item the system should reuse as much as possible previous analysis results.
\end{enumerate}

\noindent Based on these principles, symbolic executors can be divided into:

\begin{itemize}
  \item {\em offline} executors (e.g., \cite{SAGE-NDSS08}), which reason about a single path at a time. As each path is run independently of the others, results from previous runs can be immediately reused. Runs are concrete and require an input seed; the recorded trace of instructions is then executed symbolically;
 %one path at time, every run independent from the others, results can be immediately reused, each run restarts the execution of the program from the beginning. In order to perform a run, two inputs must be provided: the target program and a seed input. The program is concretely executed and a trace is recorded. Then the trace is symbolically executed. This can be seen as a form of {\em concolic} execution (see Section~\ref{ss:concrete-concolic-symbolic}).
  \item {\em online} executors (e.g., \cite{KLEE-OSDI08,CKC-TOCS12,AEG-NDSS11}, which clone the execution state at each input-dependent branch. No previous instruction is re-executed, but the continuous forking puts a burden on memory and eventually slows down the engine as the exploration proceeds. Also, isolation between states must be ensured (e.g., by emulating the effects of system calls);
%for each fork, the execution state is cloned. All active execution states are kept in memory, no need to re-execute but huge burden on memory resources. A form of {\em context switch} is often needed. Executors may stop forking at a certain point to allow progress, but then some path are ignored. Memory is saved by aggressive copy-on-write optimization (e.g., immutable state). DFS can be used as exploration strategy in order to minimize memory consumption but can be very slow at doing progress. Notice that since multiple runs may be executed in parallel, isolation must be guaranteed (e.g., keeping different states of the OS by emulating system calls).
  \item {\em hybrid} executors (e.g., \cite{MAYHEM-SP12}), which start in online mode and generate checkpoints rather than fork when memory usage or the number of concurrently active states reaches a threshold. Checkpoints maintain the symbolic execution state and replay information. When a checkpoint is picked for restoration, the concrete state is restored and the online exploration resumes.
%: mixed approach. Start with an online approach, if needed switch to offline mode by doing checkpoints. A checkpoint contains the symbolic execution state and replay information. Concrete execution state is discarded since it can be quickly recovered at runtime by using one input generated by the solver before checkpointing.
\end{itemize}

\subsection{Consistency in Concolic Executors} \mynote{Provisionally placed here} % Selective symbolic execution?

When exploring multiple paths at a time, an execution engine may execute some portions of code concretely, interleaving them with fully symbolic phases. This process, also known as {\em selective symbolic execution}, is useful to analyze a program across a full software stack without sacrificing scalability. However, it must be done carefully in order to preserve the meaningfulness of the whole exploration.

When an argument $x$ for a function call to concretize is symbolic, the engine should convert it to some concrete value in order to perform the call. Compared to the family of possible paths from executing the call symbolically, this is equivalent to corseting the exploration to a single path in the callee. When the call returns and the symbolic phase resumes, the concrete value for $x$ becomes part of the path constraints for the remainder of the exploration. However, a large number of paths may then be excluded.

\cite{CKC-TOCS12} presents the first systematic approach to consistently cross the symbolic/concrete boundary in both directions. The work describes a strategy to deal with constraints introduced on symbolic values as a consequence of concretization, and introduces a number of consistency models - where a state is {\em consistent} when there exists a feasible path to it from the initial state - which suit different analyses.

Constraints updated to account for concrete values are marked as {\em soft}, and whenever a branch in the symbolic domain is disabled because of a soft constraint, execution goes back and picks a value for the concrete call that would enable that branch.

%When execution returns to the symbolic domain, we have observed that updating constraints to reflect a concrete assignment might result in a corseting of the family of future paths that can be explored. Such constraints are marked in ~\cite{CKC-TOCS12} as {\em soft}, and whenever a branch in the symbolic domain is disabled because of a soft constraint, execution goes back and picks a value for the concrete call that would enable that branch.

\subsection{Optimization strategies} \mynote{[D] Does not belong here, functions only!}
\label{function-summaries}

\subsubsection{Function caching} A function $f$, and more in general any part of a program, may be called multiple times during the execution of a program. These invocations may occur always at the same calling context or at different ones. The traditional symbolic execution approach requires to symbolically execute $f$ every time it is called. \cite{G-POPL07} proposes a compositional approach that dynamically generates {\em function summaries}, allowing the symbolic execution engine to effectively reuse prior discovered analysis results. A similar idea has been also proposed by~\cite{BCE-TACAS08}. Their main intuition is that if two program states differ only for some program values that are not read later, the executions generated by these two program states will produce the same
%subsequent
side effects. For this reason, side effects of a portion of code can be cached and possibly later reused. Since the two techniques are almost equivalent, our discussion will follow~\cite{G-POPL07}. %we further discuss function summaries as introduced by~\cite{G-POPL07}.

\paragraph{Definition of function summaries} A function summary $\phi_f$ for a function $f$ is defined as a propositional logic formula. It can be computed by successive iterations and defined as a disjunction of formulas $\phi_w$ of the form $\phi_w = {pre}_w \wedge post_w$, where $w$ is a possible execution path of function $f$, $pre_w$ is a conjunction of constraints over the inputs of $f$, and $post_w$ is a conjunction of constraints over the outputs of $f$. Formally, $\phi_f = \bigvee \phi_w$.  

\paragraph{Using function summaries} Whenever a function $f$ is called, the symbolic execution engine checks whether a summary $\phi_w$ of $f$ with $pre_w$ compliant with the current path constraints is available. If so, the post conditions $post_w$ are added to the current symbolic state. Otherwise, if no matching summary is found, a new function summary is computed.

\paragraph{Computing function summaries} Function summaries can be computed dynamically: whenever there is an invocation of a function $f$, $pre_w$ is obtained from the current set of constraints over the input of $f$, while $post_w$ is given by tracking constraints over the \mynote{[D] no symbolic?}concolic\footnote{{\em [D] If this technique applies to concolic executors only we should say it upfront!}} execution of function $f$ over some concrete inputs that are compliant with $pre_w$. Notice that $pre_w$ defines an equivalence class of concrete executions that result in executions characterized by $post_w$. 

\paragraph{Issues} If the symbolic execution engine cannot reason on one or more statements contained in a function $f$, then the generated summary cannot be \mynote{[D] blindly}blindly reused. For instance, consider a function that contains a call to an external function (e.g., a system call) or to a {\em complex} one (e.g., a hash function). In this scenario, even if a matching function summary is found, the related post conditions $post_w$ may not be valid since they have been generated over a concrete execution and thus cannot be generalized. % robust hash function
