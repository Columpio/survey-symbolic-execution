% !TEX root = main.tex

\begin{figure}[t]
\centering
\includegraphics[width=0.35\columnwidth]{images/concrete-abstract.eps} 
\caption{Concrete and abstract excution machine models.}
\label{fig:concrete-symbolic}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\myinput{executors}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\myinput{memory}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\myinput{complex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Loops}
\label{se:loops}

Loops are one of the main cause for path explosion in symbolic execution. Indeed, each iteration of a loop can be seen as a {\tt IF-GOTO} statement, leading to a conditional branch in the execution tree. If the loop condition involves one or more symbolic values, the number of generated branches may even be infinite. For instance, consider the following example (taken from~\cite{CS-CACM13}):
    \begin{lstlisting}[basicstyle=\ttfamily\small]
    1.  int N = sym_input(); // e.g., read
    2.  while (N > 0) {
    3.    N = sym_input();  
    4.  }
    \end{lstlisting}
The path constraint set of any final state will contain:
  \[ \left ( \bigwedge_{i \in [1, n]]} N_i > 0 \right ) \wedge (N_{n+1} \leq 0) \]
where $N_i$ is the symbol introduced at the $i$-th iteration.\\

The problem of path explosion due to symbolic execution of loops has been attacked from different sides. A first natural strategy adopted by many symbolic engine is to limit the loop exploration up to a certain number of iterations. Obviously, this may lead to missing interesting paths in the program. For this reason, some prior works, such as~\cite{AEG-NDSS11}, had also considered the opposite strategy, allowing the engine to fully explore some loops. Indeed, this has been shown to be effective in some application contexts such as security (e.g., identidication fo buffer overflows) where interesting behavior may happen at the boundaries.

Using static or dynamic analysis techniques, it may be possible to derive some properties over a loop of a program. These can be exploited by an engine to significantly prune branching paths. For instance, knowing the exact number of iterations or, at least a constant upper bound, can significantly help the engine. Section~\ref{precontioned-symbolic-execution} provides a more general discussion of how preconditions can help symbolic execution.

Many prior works have instead proposed to replace in the symbolic execution tree the possibly infinite states generated by a loop with a {\em summary} of its side-effects. An approximation of the side-effects of a loop can be obtained by computing a {\em fixpoint} (see, e.g.,~\cite{KKM-USEC05,BNS-SP06,CFB-ACSAC06})). If a program contains an assertion (i.e., a property that should hold) after the loop, this can be exploited by a symbolic engine for automatically discovering some invariants over the loop. In~\cite{PV-SPIN04}, this is achieved by iteratively using invariant straightening and approximation techniques. 

\cite{GL-ISSTA11} presents a technique that automatically derives partial summarizations for loops. A loop summarization is formalized similarly to a function summary (see Section~\ref{function-summaries}), using a set of preconditions $pre_{loop}$ and a set of postconditions $post_{loop}$. These are computed dynamically during the symbolic execution by reasoning on the dependency among loop conditions and symbolic variables. As soon as a loop summary is computed, it is cached for possibly subsequent reuse. This not only allows the symbolic engine to avoid redundant executions of the same loop under the same program state, but also make it possible to generalize the loop summary to cover even different executions of the same loop that run under different conditions. A main limitation of this approach is that it can generate summaries only for loops that interactively manipulate symbolic variable by a constant non-zero amount.

On the other hand, \cite{SST-ATVA13} has introduced a technique that analyzes cyclic paths in the control flow graph of a given program and produces {\em templates} that declarative describe the program states generated by these portions of code into a symbolic execution tree. By exploiting templates, the symbolic execution engine needs to explore a significant reduced number of program states. A drawback of this approach is that templates introduce quantifiers into the path constraints. In turn, this may significantly increase the burden on the constraint solver.

It has been also observed that loop executions may strictly depend on input features. {\em Loop-extended symbolic execution} (LESE)~\cite{SPM-ISSTA09} is able to effectively explore a loop whenever a grammar describing the input program is available. By relating {\em trip counts} (i.e., number of iterations for loops) with features of the program input, the program states generated by a loop can be explored in a very effective manner.

\begin{comment}
Many prior works have targeted the problem of mitigating the path explosion effect due to symbolic execution of loops. We briefly discuss the main ideas introduced by these papers. 
\begin{itemize}

  \item {\em preconditions}: the symbolic execution of a loop can be made easier if some preconditions are known on the symbolic variables involved in the loop. For instance, if the number of loop iterations is known, the engine can drastically prune branching paths. For instance, this information may be determined using some static analysis techniques. Section~\ref{precontioned-symbolic-execution} provides a more general discussion of how preconditions can help symbolic execution.

  \item {\em fixed vs fully exploration}: depending on the goal, a symbolic engine may decide to fully explore a loop (e.g., see heuristics presented in~\cite{AEG-NDSS11} and discussed in Section~\ref{heuristics}) or to explore only a fixed number of iterations (e.g., up to 3 iterations) in order to avoid path explosion.

  \item {\em approximations}: effects of a loop are often approximated using {\em fixpoints} (e.g., in~\cite{KKM-USEC05,BNS-SP06,CFB-ACSAC06}). A fixpoint F is an approximation of the effect of loop body on an execution state. F approximates the state after the execution of loop whenever the initial state before the loop was F (?). Transforming an execution state to a fixpoint state is defined as widening. Construction of the fixpoint:
  \begin{itemize}
    \item S1: state after first iteration
    \item S2: state after second iteration
    \item compare S1 and S2: assign bottom to each symbol that has been altered
    \item repeat until there is no difference between Si and Si+1
    \item if there is a branch inside the loop, then either the branch is known or its condition is on a symbol which has been assign to bottom. In this case, two parallel states are created and then compared.
  \end{itemize}

  \item {\em loop invariant symbolic execution (LISE)}: Loop invariants can be discovered automatically using iterative techniques such as explained in~\cite{PV-SPIN04}, through the use of invariant straightening and approximation. The main idea is to work backward from a property that should be checked and then systematically applies approximation to reach termination. This approach has been later extended for parallel programs in~\cite{SZ-VMCAI12}.

  \item {\em loop summarization}: \cite{GL-ISSTA11} presents a technique that automatically derives partial summarizations for loop executions. A loop summarization is formalized similarly to a function summary (see Section~\ref{function-summaries}), using a set of preconditions $pre_{loop}$ and a set of postconditions $post_{loop}$. These are computed dynamically during the symbolic execution by reasoning on the dependency among loop conditions and symbolic variables. As soon as a loop summary is computed, it is cached for possibly subsequent reuse. This not only allows the symbolic engine to avoid redundant executions of the same loop under the same program state, but also make it possible to generalize the loop summary to cover even different executions of the same loop that run under different conditions. A main limitation of this approach is that it can generate summaries only for loops that interactively manipulate symbolic variable by a constant non-zero amount.

  \item {\em loop-extended symbolic execution (LESE)}: \cite{SPM-ISSTA09} has introduced a novel technique called LESE that symbolically tracks {\em trip counts} (i.e., number of times each loop is executed) and relate this information to features of the program input. A practical drawback of this technique is that a specification of the input grammar must be provided by the user to the symbolic execution engine.

  \item {\em compact symbolic execution}: \cite{SST-ATVA13} has introduced a technique that analyzes cyclic paths in the control flow graph of a given program and generates {\tt templates} that declarative describe the program states generated by these portions of code into a symbolic execution tree. By exploiting these templates, the symbolic execution engine needs to explore a significant reduced number of program states. A drawback of this approach is that templates introduce quantifiers into the path constraints. In turn, this can significantly increase the burden on the constraint solver.

  \item \cite{ST-ISSTA12} and~\cite{OT-ATVA11} present two technique for driving the symbolic execution of program toward a given target, even in presence of cyclic paths such as loops.\mynote{[E] non so se vale la pena discutere i dettagli}
\end{itemize}

Notice that detection/analysis of loops can be done using techniques such as~\cite{SGL-TOPLAS96} (e.g., in~\cite{CFB-ACSAC06}).
\end{comment}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\iffalse
\section{Subroutines and recursion}
\label{se:recursion}
\fi

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\myinput{environment}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\myinput{explosion}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\myinput{constraints}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\myinput{binary}


