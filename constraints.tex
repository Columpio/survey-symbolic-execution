% !TEX root = main.tex

\section{Constraint solving}

Constraint-satisfaction problems arise in many domains, including analysis, testing, and verification of software programs. Constraint solvers are decision procedures for problems expressed in logical formulas: for instance, the boolean satisfiability problem (also known as SAT) aims to determine whether there exists an interpretation of the symbols of a formula that makes it true. Although SAT is a well-known NP-complete problem, recent advances have moved the boundaries for what is intractable when it comes to practical applications~\cite{SMT-CACM11}. 

Observe that some problems are more naturally described with languages that are more expressive than the one of boolean formulas with logical connectives. For this reason, satisfiability modulo theories (SMT) generalize the SAT problem with supporting theories to capture formulas involving, for instance, linear arithmetic inequalities and operations over arrays. SMT solvers map the atoms in an SMT formula to fresh boolean variables: a SAT decision procedure checks the rewritten formula for satisfiability, and a theory solver checks the model generated by the SAT procedure. We have informally discussed the theory of bit-vectors and arrays in Section \missing.

In a symbolic executor, constraint solving plays a crucial role in checking the feasibility of a path, generating assignments to symbolic variables, and verifying assertions. The two more popular solvers used in symbolic executors are STP and Z3. ~\cite{STP-CAV07,STP-TR07} is an SMT solver with bitvector and array theories initially developed at Stanford and employed in, e.g., ~\cite{EXE-CCS06,KLEE-OSDI08,MineSweeper-BOTNET08,AEG-NDSS11}. ~\cite{Z3-TACS08} is an SMT solver developed at Microsoft with support for nonlinear arithmetic, bitvector, and array theories, and is used in, e.g., ~\cite{MAYHEM-SP12,SAGE-QUEUE12,FIRMALICE-NDSS15}. ~\cite{CVC3-CAV07} supports theories for linear arithmetic, bitvectors, arrays, and quantifiers, and is employed as SMT solver in ~\cite{PATHFINDER-ASE10} along with ~\cite{CHOCO} for integer/real constraints and ~\cite{CORAL-NFM11} for complex mathematical constraints. Modern symbolic executors can typically choose between different underlying solvers through a common API, and resort to a native interface to a specific solver for better performance.
%only for efficiency reasons.

%For instance, many solvers have the development of ~\cite{PATHFINDER-ASE10} can use a large number of SMT solvers, including Yices, 
%~\cite{YICES-CAV06} is an incremental solver with support for rational and integer linear arithmetic, bitvectors, and arrays, and was originally used in 
%In Table~\ref{tab:solvers} we report a number of constraint solving tools used in popular symbolic execution engines.

\iffalse
\begin{figure}[ht]
  \centering
  \begin{adjustbox}{width=1\columnwidth}
  \begin{small}
  \begin{tabular}{| l | p{8cm} | p{4cm} |}
    \hline      
    Constraint solver & Description & Used in  \\ \hline\hline
    \cite{STP-TR07} & SMT + bitvectors, arrays & ~\cite{EXE-CCS06,KLEE-OSDI08,MineSweeper-BOTNET08,AEG-NDSS11}, SPF? \\
    \cite{Z3-TACS08} & SMT + (non)linear arithmetic, bitvectors, arrays & ~\cite{FIRMALICE-NDSS15,MAYHEM-SP12}, SAGE \\
    \cite{CVC3-CAV07} & SMT + linear arithmetic, bitvectors, arrays, quantifiers & SPF \\
    \cite{YICES-CAV06} & SMT + rational and integer linear arithmetic, bitvectors, arrays & originally in SPF\\
    \hline  
  \end{tabular}
  \end{small}
  \end{adjustbox}
  \caption{List of constraint solvers.}
  \label{tab:solvers}
\end{figure}
\fi

However, despite the significant advances observed over the past few years -- which also made symbolic execution practical in the first place~\cite{CS-CACM13} -- constraint solving remains the main performance bottleneck in symbolic execution engines. Several optimizations have thus been developed in order to reduce both the number of invocations of the solver and the size of the formulas to check, so to avoid scalability problems arising when too large queries result in blowing the solver up. We discuss a number of such techniques in the upcoming section. We will then present other optimizations that become possible in the setting of symbolic execution.

\subsection{Constraint Optimization}

We identified two orthogonal approaches in the literature regarding constraint optimization in symbolic executors: {\em constraint reduction} techniques aim at simplify constraints fed to a solver by rewriting them into a shorter form, while techniques for {\em reuse of constraint solutions} explore the space-time trade-off of retrieving previously computed query results rather than repeating expensive satisfiability checks.

\subsubsection{Constraint Reduction}
A common optimization approach followed by both solvers and symbolic executors is to reduce constraints into simpler forms. For example, the {\em expression rewriting} optimization can apply classical techniques from optimizing compilers such as constant folding, strength reduction, and simplification of linear expressions~\cite{KLEE-OSDI08}.

~\cite{EXE-CCS06} introduces a {\em constraint independence} optimization that exploits the fact that a set of constraints can frequently be divided into multiple independent subsets of constraints. This optimization interacts well with query result caching strategies, and offers an additional advantage when an engine asks the solver about the satisfiability of a specific constraint\mynote{[D] yet a bit unclear to me}, as it removes irrelevant constraints from the query. Real programs have many independent branches, which can often introduce irrelevant constraints that add up quickly.

Another fact that can be exploited by reduction techniques is that the natural structure of programs can lead to the introduction of more specific constraints for some variables as the execution proceeds. As path conditions are generated by conjoining new terms to an old sequence, it might become possible to rewrite and optimize existing constraints. For instance, adding an equality constraint of the form $x:=5$ enables not only the simplification to true of other constraints over the value of the variable (e.g., $x>0$), but also the substitution of the symbol $x$ with the associated concrete value in the other subsequent constraints involving it. The latter optimization is also known as {\em implied value concretization}~\cite{KLEE-OSDI08}.

In a similar spirit, \cite{CKC-TOCS12} introduces a bitfield-theory expression simplifier to replace with concrete values parts of a symbolic variable that are masked away by bit operations. For instance, if $x$ is a 4-bit symbolic value, the most significant bit in the expression $x\,|\,4$ is known to be one. The simplifier can propagate information across the tree representation of an expression, and if all bits in an expression are known, it replaces the expression with the corresponding constant.
 
%path conditions in a symbolic executor are typically generated by conjoining a new term to an existing (and possibly satisfiable) sequence of constraints. As the exploration proceeds, the natural structure of programs means that constraints might become more specific for some variables, and constraints can be rewritten accordingly. 

\subsubsection{Reuse of Constraint Solutions}
\label{ss:constraint-reuse}

The idea of reusing previously computed results to speed constraint solving up can be particularly effective in the setting of a symbolic executor, especially when combined with other techniques such as constraint independence optimization. Most reuse approaches for constraint solution are currently based on syntactic or semantic equivalence of the constraints.

~\cite{EXE-CCS06} caches the result of satisfiability queries and constraint solutions in order to avoid calling the solver when possible. A cache is managed by a server process that can receive queries by multiple parallel instances of the execution engine each exploring a different program state.

~\cite{KLEE-OSDI08} implements an incremental optimization strategy called {\em counterexample caching}. A tree representation-based cache maps constraint sets to concrete variable assignments, or to a special null value when a constraint set is unsatisfiable. When an unsatisfiable set in the cache is a subset for a given constraint set $S$, $S$ is deemed as unsatisfiable as well. Conversely, when the cache contains a solution for a superset of $S$, the solution trivially satisfies $S$ too. Finally, when the cache contains a solution for one or more subsets of $S$, the algorithm tries substituting in all the solutions to check whether a satisfying solution for $S$ can be found.

{\em Memoized symbolic execution}~\cite{MEMO-ISSTA12} introduces a new approach for a more efficient application of symbolic execution. The work is motivated by the observation that applying symbolic execution often requires several successive runs of the technique on largely similar underlying problems, e.g., finding a bug and then examining the program again to check the validity of the fix. A trie-based data structure compactly encodes the choices taken when exploring different paths, allowing successive run to reuse previously computed results where possible.

The Green framework~\cite{GREEN-FSE12} explore constraint solution reuse across runs of not only the same program, but also similar programs, different programs, and different analyses. Constraints are distilled into their essential parts through a {\em slicing} transformation and represented in a canonical form to achieve good reuse, even within a single analysis run. ~\cite{JGY-ISSTA15} presents an extension to the Green framework that supports constraint reuse based on the logical implication relations among constraints, leading to better reuse and faster execution time for the symbolic analysis.

\subsection{Other Optimizations in Symbolic Executors}
In this section we present a number of optimization that become possible in the setting of a symbolic executor to reduce the time spent in the constraint solver.

\subsubsection{Lazy constraints}
~\cite{UCKLEE-USEC15} adopts a timeout approach for constraint solver queries. In their initial experiments, the authors traced most timeouts to symbolic division and remainder operations, with the worst cases occurring when an unsigned remainder operation had a symbolic value in the denominator.
They thus implemented a solution that works as follow: when the executor encounters a branch statement involving an expensive symbolic operation, it will take both the true and false branches and add a {\em lazy} constraint on the result of the expensive operation to the path conditions. When the exploration reaches a state that satisfies some goal (e.g., an error is found), ~\cite{UCKLEE-USEC15} will check for the feasibility of the path, and suppress it if deemed as unreachable in a real execution.

Compared to the {\em eager} approach of checking the feasibility of a branch as encountered (Section~\ref{ss:unrealizable-paths}), a lazy strategy may lead to a larger number of active states, and in turn more solver queries. However, the authors report that the delayed queries are in many cases more efficient than their eager counterparts: additional path constraints added after a lazy one can narrow down the solution space considered by the solver.

\subsubsection{Concretization}
~\cite{CS-CACM13} discusses limitations of classical symbolic execution in the presence of formulas that cannot be (efficiently) solved by constraint solvers.
    \begin{lstlisting}[basicstyle=\ttfamily\small]
    int non_linear(int v) {
      return (v*v) % 50;
    }
    
    void test(int x, int y) {
      z = non_linear(y);
      if (z == x) {
        if (x > y + 10) ERROR;  
      }
    }
    \end{lstlisting}

\noindent In the code fragment above, the engine will generate a constraint of the form $\alpha_x = (\alpha_y*\alpha_y)\,\%\,50$ for the true branch in the first {\tt if} statement in {\tt test}. A solver that does not support nonlinear arithmetic will fail to generate any input for the program.

A concolic executor will generate some random input for the program and execute it both concretely and symbolically: a possible value from the concrete execution can be used for a symbolic operand involved in a formula that is inherently hard for the solver, albeit at the cost of sacrificing completeness in the exploration. For instance, in the presence of three nested branches with only one of them being nonlinear, ~\cite{DART-PLDI05} will start from a random\mynote{[D] E please check aliasing} valid input for the function, and then alter it when symbolically exploring the two linear branches. ~\cite{DART-PLDI05} resorts please to concretization also to avoid performing expensive or imprecise alias analysis on pointers.

%Notice that the use of concrete values can also avoid to perform alias analysis on pointers, which is typically very expensive. Whenever meaningful, \cite{DART-PLDI05} tries to test both valid (not {\tt NULL}) and invalid ({\tt NULL}) input pointers in order to maximize bug detection. However~\cite{DART-PLDI05} will never artificially negate a branch if that condition cannot be exercised using a concrete input. In other words, both branches of an {\tt if} statement are considered only if they are both meaningful (more precisely: \cite{DART-PLDI05} is able to generate a valid input).

%Notice that~\cite{DART-PLDI05} may generate an input using a solver by considering only a subset of branch constraints. For instance, consider constraints ($C_1, C_2, C_3$) given by three nested branches: if $C_1$ is non linear (hard to solve), it needs only to generate a random input for taking $C_1$ and then use the solver for exploring path given by $(C_2, C_3)$. A traditional symbolic execution engine may get stuck at $C_1$ and give up after some time on {\em all} the derived path. Notice that whenever a concrete input is used to overcome a hard constraint, the overall approach become incomplete.

%~\cite{CKC-TOCS12} 
%Whenever a memory access with a symbolic pointer occurs,~\cite{CKC-TOCS12} determines the page referenced by the pointer. This information is then passed to the solver to help it. To make this even more effective, the page size is reduced as much as possible (e.g., 128 bytes).
%of constraints that might be hard or impossible to reason on for a solver. For instance, 

%A significant amount of the execution time of a symbolic engine is spent invoking the constraint solver.

\iffalse
\subsection{[OLD] Dealing with unsolvable constraints} 
\iffalse
Assume to start a concrete execution with a concrete input and in parallel symbolically execute the same program. Whenever a set of constraints cannot be solved by the constraint solver, then use the concrete value to proceed into at least one branch. Example taken from~\cite{CS-CACM13}:
    \begin{lstlisting}[basicstyle=\ttfamily\small]
    int non_linear(int v) {
      return (v * v) % 50;
    }
    \end{lstlisting}
The non-linear operation inside this function can be hard for a solver. Using a concrete execution, the engine can overcome this problem, but then the precision and completeness may be affected.
\fi

Notice that the use of concrete values can also avoid to perform alias analysis on pointers, which is typically very expensive. Whenever meaningful, \cite{DART-PLDI05} tries to test both valid (not {\tt NULL}) and invalid ({\tt NULL}) input pointers in order to maximize bug detection. However~\cite{DART-PLDI05} will never artificially negate a branch if that condition cannot be exercised using a concrete input. In other words, both branches of an {\tt if} statement are considered only if they are both meaningful (more precisely: \cite{DART-PLDI05} is able to generate a valid input). Notice that~\cite{DART-PLDI05} may generate an input using a solver by considering only a subset of branch constraints. For instance, consider constraints ($C_1, C_2, C_3$) given by three nested branches: if $C_1$ is non linear (hard to solve), it needs only to generate a random input for taking $C_1$ and then use the solver for exploring path given by $(C_2, C_3)$. A traditional symbolic execution engine may get stuck at $C_1$ and give up after some time on {\em all} the derived path. Notice that whenever a concrete input is used to overcome a hard constraint, the overall approach become incomplete.
\fi

% ---------------------------------------------------------------------------------------------------
\iffalse
\subsection{Solvers}
A list of constraint solvers\mynote{Table?}:
\begin{itemize}
  \item \cite{STP-TR07}: used by~\cite{EXE-CCS06,KLEE-OSDI08,MineSweeper-BOTNET08}, used by SPF
  \item \cite{Z3-TACS08}: used by~\cite{FIRMALICE-NDSS15,MAYHEM-SP12,SAGE-QUEUE12}
  \item \cite{DISSOLVER-TR03}: initially used by \cite{SAGE-NDSS08}
  \item \cite{PPL-SCP08}: used by \cite{CFB-ACSAC06}
  \item (incremental solver) \href{http://www.cs.nyu.edu/acsys/cvc3/}{CVC3}: an automatic theorem prover for Satisfiability Modulo Theories, used by SPF
  \item (incremental solver) \href{http://yices.csl.sri.com/}{Yices}: The Yices SMT Solver~\cite{YICES-CAV06}
  \item \href{http://choco-solver.org/}{CHOCO}: A Free and Open-Source Java Library for Constraint Programming, used by SPF
  \item \href{http://www.cs.brandeis.edu/~tim/Applets/IAsolver.html}{IAsolver}: the Brandeis Interval Arithmetic Constraint Solver, used by SPF
  \item \href{https://people.csail.mit.edu/akiezun/hampi/}{Hampi}: A Solver for String Constraints, used by SPF
  \item \href{https://www.cs.umd.edu/projects/omega/}{Omega}~\cite{OMEGA-SC91}, used by SPF
  \item \href{http://pagesperso.lina.univ-nantes.fr/~granvilliers-l/realpaver/}{RealPaver}: onlinear constraint solving \& rigorous global optimization, used by SPF
  \item \href{http://smtlib.cs.uiowa.edu/}{SMT-LIB}: the satisfiability modulo theories library, used by SPF
  \item CORAL~\cite{CORAL-NFM11}: used by SPF
\end{itemize}
\fi
% ---------------------------------------------------------------------------------------------------

% ---------------------------------------------------------------------------------------------------
\iffalse
\subsection{Lazy evaluation}\mynote{citations?}
\mynote{[D] original text starts here} A technique used in practice to avoid frequent invocation of the constraint solver is {\em lazy evaluation}. The main idea is to avoid checking for contradictions at each branch condition, exploring both branches. This means that some of the states that the engine will later explore may be non-reachable during a real program execution. This allows a symbolic engine to quickly explore paths but forces it to check their consistency before using them for drawing some conclusions. The main disadvantages of this techniques are: (a) this strategy may lead to a large number of active states, (b) the time spent for checking the consistency of many states may be similar to the time spent for performing pruning in the first place.
\fi

% ---------------------------------------------------------------------------------------------------
\subsection{[OLD] Constraint optimizations - TO MOVE}
\label{constraint-optimizations}

\mynote{add \cite{S-FMCAD08} + some optimizations listed in Section~\ref{memory-model}.}

Many optimization can be applied to constraints in order to make it more solver-friendly.

\iffalse

\subsubsection{Constraint caching} Cache solver results and reuse them \mynote{to be completed}

\subsubsection{Constraint independence} tracks constraints into multiple independent subsets of constraints, This helps the system discards irrelevant constraints and adds additional cache hits.  \mynote{to be completed}

\subsubsection{Irrelevant constraint optimization} Remove from path constraints those constraints that are irrelevant in deciding the outcome of the current branch. In practice, this is done by computing the transitive closure of all the constraints. Pointer and array reference can make this hard: e.g., see details in~\cite{EXE-CCS06,EGL-ISSTA09,CUTE-FSE13}. In~\cite{KLEE-OSDI08}, this is called {\em constraint independence}: the main idea is to divide constraints in independent disjoint subsets based on the symbolic variables which they reference. Irrelevant constraints can detected and discarded.

\subsubsection{Incremental solving} Many paths common branches, then it can be beneficial to reason about subset or superset of constraints. See more details, e.g., in~\cite{KLEE-OSDI08,CUTE-FSE13}. In~\cite{KLEE-OSDI08}, they propose {\em counterexample caching} to keep a cache of counterexample based on past queries:
      \begin{itemize}
        \item if a subset of constraints has not solution, any superset does not have as well
        \item if a superset has a solution, any subset has a solution
        \item if a subset has a solution, try it for the superset
      \end{itemize}

\subsubsection{Bit-field theory expression} \cite{CKC-TOCS12} tries to simplify expression using a bit-field theory expressions: if parts of a symbolic variable are masked away by bit operations, then known bits of the symbolic variable can be replaced by their constant values. If all bits of a symbolic variable are constant, then the variable is marked as concrete.

\fi

\mynote{[D] TOCS page 24}\subsubsection{Page boundings on pointers} Whenever a memory access with a symbolic pointer occurs,~\cite{CKC-TOCS12} determines the page referenced by the pointer. This information is then passed to the solver to help it. To make this even more effective, the page size is reduced as much as possible (e.g., 128 bytes).

%{\em Concolic execution} has been originally introduced in~\cite{DART-PLDI05} and then refined by~\cite{CUTE-FSE13}. A common disadvantage of symbolic execution is that the state space can be exponential. Moreover, even when the state space is tractable it may happen that complex constraints need to be solved but these constraints are too complex for the actual solver (e.g., non-linear constraints are typically hard to solve). For this reason, it is common to exploit concolic execution. 

\subsubsection{Execution-Generated Testing (EGT)} 
Is the approach used by some papers (e.g.,~\cite{KLEE-OSDI08,EXE-CCS06}) that works by making a distinction between the concrete and symbolic state of a program: if an operation involves only concrete values, then the symbolic engine concretely execute it. This can allow symbolic execution to reason even over complex operation (e.g., non linear operations) if they involve only concrete values. EGT is often seen (\cite{CS-CACM13}) as a form of dynamic symbolic execution: this can be seen as more general term than concolic execution.