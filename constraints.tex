% !TEX root = main.tex

\section{Constraint solving}
\label{se:constraint-solving}

Constraint satisfaction problems arise in many domains, including analysis, testing, and verification of software programs. Constraint solvers are decision procedures for problems expressed in logical formulas: for instance, the boolean satisfiability problem (also known as SAT) aims to determine whether there exists an interpretation of the symbols of a formula that makes it true. Although SAT is a well-known NP-complete problem, recent advances have moved the boundaries for what is intractable when it comes to practical applications~\cite{SMT-CACM11}. 

Observe that some problems are more naturally described with languages that are more expressive than the one of boolean formulas with logical connectives. For this reason, satisfiability modulo theories (SMT) generalize the SAT problem with supporting theories to capture formulas involving, for instance, linear arithmetic inequalities and operations over arrays (see, e.g., Section~\ref{ss:fully-symbolic-memory}). SMT solvers map the atoms in an SMT formula to fresh boolean variables: a SAT decision procedure checks the rewritten formula for satisfiability, and a theory solver checks the model generated by the SAT procedure.

In a symbolic executor, constraint solving plays a crucial role in checking the feasibility of a path, generating assignments to symbolic variables, and verifying assertions. The two most popular solvers used in symbolic executors are STP and Z3. STP~\cite{STP-CAV07,STP-TR07} is an SMT solver with bitvector and array theories initially developed at Stanford and employed in, e.g., {\sc EXE}~\cite{EXE-CCS06}, {\sc KLEE}~\cite{KLEE-OSDI08}, {\sc MineSweeper}~\cite{MineSweeper-BOTNET08}, and {\sc AEG}~\cite{AEG-NDSS11}. Z3~\cite{Z3-TACS08} is an SMT solver developed at Microsoft with support for nonlinear arithmetic, bitvector, and array theories, and is used in, e.g., {\sc Mayhem}~\cite{MAYHEM-SP12}, {\sc SAGE}~\cite{SAGE-QUEUE12}, {\sc Angr}~\cite{ANGR-SSP16}. CVC3~\cite{CVC3-CAV07} is another SMT solver that supports theories for linear arithmetic, bitvectors, arrays, and quantifiers, and is employed in {\sc Java PathFinder}~\cite{PATHFINDER-ASE10} along with CHOCO~\cite{CHOCO} for integer/real constraints and CORAL~\cite{CORAL-NFM11} for complex mathematical constraints. Modern symbolic executors can typically choose between different underlying solvers through a common API, and also resort to a native interface to a specific solver for better performance.
%only for efficiency reasons.

%For instance, many solvers have the development of ~\cite{PATHFINDER-ASE10} can use a large number of SMT solvers, including Yices, 
%~\cite{YICES-CAV06} is an incremental solver with support for rational and integer linear arithmetic, bitvectors, and arrays, and was originally used in 
%In Table~\ref{tab:solvers} we report a number of constraint solving tools used in popular symbolic execution engines.

\iffalse
\begin{figure}[ht]
  \centering
  \begin{adjustbox}{width=1\columnwidth}
  \begin{small}
  \begin{tabular}{| l | p{8cm} | p{4cm} |}
    \hline      
    Constraint solver & Description & Used in  \\ \hline\hline
    \cite{STP-TR07} & SMT + bitvectors, arrays & ~\cite{EXE-CCS06,KLEE-OSDI08,MineSweeper-BOTNET08,AEG-NDSS11}, SPF? \\
    \cite{Z3-TACS08} & SMT + (non)linear arithmetic, bitvectors, arrays & ~\cite{FIRMALICE-NDSS15,MAYHEM-SP12}, SAGE \\
    \cite{CVC3-CAV07} & SMT + linear arithmetic, bitvectors, arrays, quantifiers & SPF \\
    \cite{YICES-CAV06} & SMT + rational and integer linear arithmetic, bitvectors, arrays & originally in SPF\\
    \hline  
  \end{tabular}
  \end{small}
  \end{adjustbox}
  \caption{List of constraint solvers.}
  \label{tab:solvers}
\end{figure}
\fi

However, despite the significant advances observed over the past few years -- which also made symbolic execution practical in the first place~\cite{CS-CACM13} -- constraint solving remains the main performance bottleneck in symbolic execution engines. Several optimizations have thus been developed in order to reduce both the number of invocations of the solver and the size of the formulas to check. 
%, so to avoid scalability problems arising when large queries result in blowing the solver up. 
We discuss a number of optimization techniques in the remainder of this section. 
%We will then present other optimizations that become possible in the setting of symbolic execution.

\subsection{Constraint Optimization}
\label{ss:constraint-opt}

In this section, we address two orthogonal optimization approaches to constraint optimization investigated in the symbolic execution literature: {\em constraint reduction} techniques aim at simplify constraints fed to a solver by rewriting them into a shorter form, while techniques for {\em reuse of constraint solutions} explore the space-time trade-off of retrieving previously computed query results rather than repeating expensive satisfiability checks.

\myparagraph{Constraint Reduction} 
A common optimization approach followed by both solvers and symbolic executors is to reduce constraints into simpler forms. For example, the {\em expression rewriting} optimization can apply classical techniques from optimizing compilers such as constant folding, strength reduction, and simplification of linear expressions (see, e.g., {\sc KLEE}~\cite{KLEE-OSDI08}).

{\sc EXE}~\cite{EXE-CCS06} introduces a {\em constraint independence} optimization that exploits the fact that a set of constraints can frequently be divided into multiple independent subsets of constraints. This optimization interacts well with query result caching strategies, and offers an additional advantage when an engine asks the solver about the satisfiability of a specific constraint, as it removes irrelevant constraints from the query. In fact, real programs typically have many independent branches, which can often introduce irrelevant constraints that add up quickly.

Another fact that can be exploited by reduction techniques is that the natural structure of programs can lead to the introduction of more specific constraints for some variables as the execution proceeds. As path conditions are generated by conjoining new terms to an existing sequence, it might become possible to rewrite and optimize existing constraints. For instance, adding an equality constraint of the form $x:=5$ enables not only the simplification to true of other constraints over the value of the variable (e.g., $x>0$), but also the substitution of the symbol $x$ with the associated concrete value in the other subsequent constraints involving it. The latter optimization is also known as {\em implied value concretization} and, for instance, it is employed by {\sc KLEE}~\cite{KLEE-OSDI08}.

In a similar spirit, {\sc \stwoe}~\cite{CKC-TOCS12} introduces a bitfield-theory expression simplifier to replace with concrete values parts of a symbolic variable that are masked away by bit operations. For instance, if $x$ is a 4-bit symbolic value, the most significant bit in the expression $x\,|\,1000$ is known to be one. The simplifier can propagate information across the tree representation of an expression, and if all bits in an expression are known, it replaces the expression with the corresponding constant.
 
%path conditions in a symbolic executor are typically generated by conjoining a new term to an existing (and possibly satisfiable) sequence of constraints. As the exploration proceeds, the natural structure of programs means that constraints might become more specific for some variables, and constraints can be rewritten accordingly. 

%\subsubsection{Reuse of Constraint Solutions}
%\label{ss:constraint-reuse}

\myparagraph{Reuse of Constraint Solutions} 
The idea of reusing previously computed results to speed constraint solving up can be particularly effective in the setting of a symbolic executor, especially when combined with other techniques such as constraint independence optimization. Most reuse approaches for constraint solution are currently based on syntactic or semantic equivalence of the constraints.

{\sc EXE}~\cite{EXE-CCS06} caches the result of satisfiability queries and constraint solutions in order to avoid calling the solver when possible. A cache is managed by a server process that can receive queries by multiple parallel instances of the execution engine each exploring a different program state.

{\sc KLEE}~\cite{KLEE-OSDI08} implements an incremental optimization strategy called {\em counterexample caching}. A tree representation-based cache maps constraint sets to concrete variable assignments, or to a special null value when a constraint set is unsatisfiable. When an unsatisfiable set in the cache is a subset for a given constraint set $S$, $S$ is deemed as unsatisfiable as well. Conversely, when the cache contains a solution for a superset of $S$, the solution trivially satisfies $S$ too. Finally, when the cache contains a solution for one or more subsets of $S$, the algorithm tries substituting in all the solutions to check whether a satisfying solution for $S$ can be found.

{\em Memoized symbolic execution}~\cite{MEMO-ISSTA12} introduces a new approach for a more efficient application of symbolic execution. The work is motivated by the observation that applying symbolic execution often requires several successive runs of the technique on largely similar underlying problems, e.g., finding a bug and then examining the program again to check the validity of the fix. A trie-based data structure compactly encodes the choices taken when exploring different paths, allowing successive runs to reuse previously computed results where possible.

The Green framework~\cite{GREEN-FSE12} explores constraint solution reuse across runs of not only the same program, but also similar programs, different programs, and different analyses. Constraints are distilled into their essential parts through a {\em slicing} transformation and represented in a canonical form to achieve good reuse, even within a single analysis run. ~\cite{JGY-ISSTA15} presents an extension to the framework that supports constraint reuse based on the logical implication relations among constraints, leading to better reuse and faster execution time for the symbolic analysis.

%\subsection{Other Optimizations in Symbolic Executors}
\subsection{Reducing the Pressure on Constraint Solvers}
\label{ss:reducing-constraint-solver-pressure}

In this section we present a number of optimizations that become possible in the setting of a symbolic executor to reduce the time spent in the constraint solver.

\myparagraph{Lazy Constraints}
\cite{UCKLEE-USEC15} adopts a timeout approach for constraint solver queries. In their initial experiments, the authors traced most timeouts to symbolic division and remainder operations, with the worst cases occurring when an unsigned remainder operation had a symbolic value in the denominator.
They thus implemented a solution that works as follow: when the executor encounters a branch statement involving an expensive symbolic operation, it will take both the true and false branches and add a {\em lazy} constraint on the result of the expensive operation to the path conditions. When the exploration reaches a state that satisfies some goal (e.g., an error is found), the algorithm will check for the feasibility of the path, and suppress it if deemed as unreachable in a real execution.

Compared to the {\em eager} approach of checking the feasibility of a branch as encountered (Section~\ref{ss:unrealizable-paths}), a lazy strategy may lead to a larger number of active states, and in turn to more solver queries. However, the authors report that the delayed queries are in many cases more efficient than their eager counterparts: the path constraints added after a lazy constraint can in fact narrow down the solution space for the solver.

\begin{figure}[t]
\begin{center}
\begin{tabular}{c}
\begin{lstlisting}[basicstyle=\ttfamily\small]
int non_linear(int v) {
   return (v*v) % 50;
}

void test(int x, int y) {
   z = non_linear(y);
   if (z == x) {
      if (x > y + 10) ERROR;  
   }
}
\end{lstlisting}
\end{tabular}
\end{center}
\caption{Non-linear constraints example.}
\label{fi:non-linear-constraints}
\end{figure}


\medskip\noindent{\bf Concretization.}
\cite{CS-CACM13} discusses limitations of classical symbolic execution in the presence of formulas that cannot be (efficiently) solved by constraint solvers. In the code fragment of Figure~\ref{fi:non-linear-constraints}, the engine generates a constraint of the form $\alpha_x = (\alpha_y*\alpha_y)\,\%\,50$ for the true branch in the first {\tt if} statement in {\tt test}. A solver that does not support nonlinear arithmetic fails to generate any input for the program.

A concolic executor generates some random input for the program and execute it both concretely and symbolically: a possible value from the concrete execution can be used for a symbolic operand involved in a formula that is inherently hard for the solver, albeit at the cost of sacrificing soundness in the exploration. For instance, in the presence of three nested branches with only one being nonlinear, {\sc DART}~\cite{DART-PLDI05} will start from a random valid input for the function, and then alter it when symbolically exploring the two linear branches. The work resorts to concretization also to avoid performing expensive or imprecise alias analysis on pointers. % with only one of them being

To partially overcome the incompleteness due to concretization,~\cite{PRV-ISSTA11} suggests to consider {\em all} the path constraints collectable over a path before binding one or more symbols to specific concrete values. Indeed, {\sc DART}~\cite{DART-PLDI05} concretizes symbols based on the path constraints collected up to a target branch. In this manner, a constraint contained in a subsequent branch in the same path is not considered and it may be not satisfiable due to already concretized symbols. If this happen, {\sc DART} restarts the execution with different random concrete values, hoping to be able to satisfy the subsequent branch. The approach presented in~\cite{PRV-ISSTA11} requires to detect {\em solvable} constraints along a full path and to delay concretization as much as possible.

\myparagraph{Memory Page Size}
In {\sc \stwoe}~\cite{CKC-TOCS12}, when a symbolic pointer is dereferenced the engine determines which memory pages are referenced by it and passes their contents to the solver. As large page sizes can overwhelm the solver, they use small pages of configurable size rather than the default 4KB pages. The authors report significant performance benefits from using pages of smaller size.
