% !TEX root = main.tex

\section{Loops}
\label{se:loops}

Loops are one of the main causes of path explosion: each iteration of a loop can be seen as an {\tt if-goto} statement, leading to a conditional branch in the execution tree. If the loop condition involves one or more symbolic values, the number of generated branches may be potentially infinite. 

\begin{figure}[t]
\begin{center}
\begin{tabular}{c}
\begin{lstlisting}[basicstyle=\ttfamily\small]
1.  int x = sym_input(); // e.g., read from file
2.  while (x > 0) {
3.     x = sym_input();  
4.  }
\end{lstlisting}
\end{tabular}
\end{center}
\caption{Loop example with input read from the environment~\protect\cite{CS-CACM13}.}
\label{fi:example-loop}
\end{figure}


\boxedexample{Consider the code fragment of Figure~\ref{fi:example-loop}~\cite{CS-CACM13}, where \texttt{sym\_input()} is an external routine that interacts with the environment (e.g., by reading input data from a network) and returns a fresh symbolic input. The path constraint set at any final state has the form:
\[ \pi = \left ( \bigwedge_{i \in [1, k]} \alpha_i > 0 \right ) \wedge (\alpha_{k+1} \leq 0) \]
where $k$ is the number of iterations and $\alpha_i$ is the symbol produced by \texttt{sym\_input()} at the $i$-th iteration.}

\noindent The problem of path explosion due to symbolic execution of loops has been attacked from different sides. A first natural strategy adopted by many symbolic engines is to limit the loop exploration up to a certain number of iterations. Obviously, this may lead to missing interesting paths in the program. For this reason, some works (e.g., {\sc AEG}~\cite{AEG-NDSS11}) have also considered the opposite strategy, allowing the engine to fully explore some loops. To mitigate the path explosion problem, only a single instance of the symbolic executor is allowed to fully unroll a loop, while other instances conservatively explore other paths. This approach has been shown to be effective in some application contexts such as security (e.g., identification of buffer overflows) where interesting behavior may be observed at the loop boundaries.

By using static or dynamic analysis techniques, it may be possible to derive properties over a loop that can be exploited by the symbolic engine to significantly prune branching paths. For instance, knowledge of the exact number of loop iterations - or at least a constant upper bound on it - can significantly help the engine. Section~\ref{precontioned-symbolic-execution} provides a more general discussion of how preconditions can help symbolic execution. Nevertheless, even symbolic execution can be used to derive loop invariants. Indeed, if a program contains an assertion after the loop, the approach presented in~\cite{PV-SPIN04} works backwards from the property to be checked and it iteratively applies approximation to derive loop invariants. The main idea is to pick the asserted property as the initial invariant candidate and then to exploit symbolic execution to check whether this property is inductive. If the invariant cannot be verified for some loop paths, it is replaced by a different invariant. The next candidate for the invariant is generated by exploiting the path constraints for the paths on which the verification has failed. Additional refinements steps are performed to guarantee termination.

%this can be exploited by a symbolic engine for automatically discovering some invariants over the loop. In~\cite{PV-SPIN04}, this is achieved by iteratively using \mynote{[D] Define?} invariant strengthening and approximation techniques. 

\cite{GL-ISSTA11} presents a technique that automatically derives partial summarizations for loops. A loop summarization is similar to a function summary (Section~\ref{ss:caching}), using a set of preconditions and a set of postconditions. These are computed dynamically during the symbolic execution by reasoning on the dependencies among loop conditions and symbolic variables. As soon as a loop summary is computed, it is cached for possibly subsequent reuse. This not only allows the symbolic engine to avoid redundant executions of the same loop under the same program state, but also makes it possible to generalize the loop summary to cover even different executions of the same loop that run under different conditions. A main limitation of this approach is that it can generate summaries only for loops that iteratively update symbolic variables across loop iterations by adding a constant, non-zero amount.

\cite{SST-ATVA13} introduces a technique of a different flavor that analyzes cyclic paths in the control flow graph of a given program and produces {\em templates} that declaratively describe the program states generated by these portions of code into a symbolic execution tree. By exploiting templates, the symbolic execution engine needs to explore a significantly reduced number of program states. A drawback of this approach is that templates introduce quantifiers in the path constraints: in turn, this may significantly increase the burden on the constraint solver.



% [D] I don't think mentioning trip counts adds value to the discussion, better keep thing simple
% By relating {\em trip counts} (i.e., number of iterations for loops) with features of the program input
It has also been observed that loop executions may strictly depend on input features. {\em Loop-extended symbolic execution}~\cite{SPM-ISSTA09} is able to effectively explore a loop whenever a grammar describing the input program is available. Relating the number of iterations with features of the program input can guide the exploration of the program states generated by a loop.

%%% previous draft below %%%

\begin{comment}
Many prior works have targeted the problem of mitigating the path explosion effect due to symbolic execution of loops. We briefly discuss the main ideas introduced by these papers. 
\begin{itemize}

  \item {\em preconditions}: the symbolic execution of a loop can be made easier if some preconditions are known on the symbolic variables involved in the loop. For instance, if the number of loop iterations is known, the engine can drastically prune branching paths. For instance, this information may be determined using some static analysis techniques. Section~\ref{precontioned-symbolic-execution} provides a more general discussion of how preconditions can help symbolic execution.

  \item {\em fixed vs fully exploration}: depending on the goal, a symbolic engine may decide to fully explore a loop (e.g., see heuristics presented in~\cite{AEG-NDSS11} and discussed in Section~\ref{heuristics}) or to explore only a fixed number of iterations (e.g., up to 3 iterations) in order to avoid path explosion.

  \item {\em approximations}: effects of a loop are often approximated using {\em fixpoints} (e.g., in~\cite{KKM-USEC05,BNS-SP06,CFB-ACSAC06}). A fixpoint F is an approximation of the effect of loop body on an execution state. F approximates the state after the execution of loop whenever the initial state before the loop was F (?). Transforming an execution state to a fixpoint state is defined as widening. Construction of the fixpoint:
  \begin{itemize}
    \item S1: state after first iteration
    \item S2: state after second iteration
    \item compare S1 and S2: assign bottom to each symbol that has been altered
    \item repeat until there is no difference between Si and Si+1
    \item if there is a branch inside the loop, then either the branch is known or its condition is on a symbol which has been assign to bottom. In this case, two parallel states are created and then compared.
  \end{itemize}

  \item {\em loop invariant symbolic execution (LISE)}: Loop invariants can be discovered automatically using iterative techniques such as explained in~\cite{PV-SPIN04}, through the use of invariant straightening and approximation. The main idea is to work backward from a property that should be checked and then systematically applies approximation to reach termination. This approach has been later extended for parallel programs in~\cite{SZ-VMCAI12}.

  \item {\em loop summarization}: \cite{GL-ISSTA11} presents a technique that automatically derives partial summarizations for loop executions. A loop summarization is formalized similarly to a function summary (see Section~\ref{function-summaries}), using a set of preconditions $pre_{loop}$ and a set of postconditions $post_{loop}$. These are computed dynamically during the symbolic execution by reasoning on the dependency among loop conditions and symbolic variables. As soon as a loop summary is computed, it is cached for possibly subsequent reuse. This not only allows the symbolic engine to avoid redundant executions of the same loop under the same program state, but also make it possible to generalize the loop summary to cover even different executions of the same loop that run under different conditions. A main limitation of this approach is that it can generate summaries only for loops that interactively manipulate symbolic variable by a constant non-zero amount.

  \item {\em loop-extended symbolic execution (LESE)}: \cite{SPM-ISSTA09} has introduced a novel technique called LESE that symbolically tracks {\em trip counts} (i.e., number of times each loop is executed) and relate this information to features of the program input. A practical drawback of this technique is that a specification of the input grammar must be provided by the user to the symbolic execution engine.

  \item {\em compact symbolic execution}: \cite{SST-ATVA13} has introduced a technique that analyzes cyclic paths in the control flow graph of a given program and generates {\tt templates} that declarative describe the program states generated by these portions of code into a symbolic execution tree. By exploiting these templates, the symbolic execution engine needs to explore a significant reduced number of program states. A drawback of this approach is that templates introduce quantifiers into the path constraints. In turn, this can significantly increase the burden on the constraint solver.

  \item \cite{ST-ISSTA12} and~\cite{OT-ATVA11} present two technique for driving the symbolic execution of program toward a given target, even in presence of cyclic paths such as loops.\mynote{[E] non so se vale la pena discutere i dettagli}
\end{itemize}

Notice that detection/analysis of loops can be done using techniques such as~\cite{SGL-TOPLAS96} (e.g., in~\cite{CFB-ACSAC06}).
\end{comment}
